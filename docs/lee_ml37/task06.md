# Task06 卷积神经网络

## 1 CNN特点（为什么用CNN?）

&emsp;&emsp;CNN可用于影像处理，用比较少的参数进行模型训练
- 使用小区域：对一个神经网络来说，假设要判断一个图片中有没有某一个部分出现，其实不需要看整张图，只要看该图的一小部分即可。
- 使用小匹配：同样的匹配在一幅图中，可能会出现在不同图的其他地方，但是代表的是同样的含义，它们有同样的形状，可以用同样的神经网络处理。
- 使用下采样：例如将一个图片变成远来十分之一的大小，不会影响对图片的理解，可用相同的神经网络处理。

## 2 CNN架构

![chapter21-8.png](./images/ch06/chapter21-8.png)

1. 将一张图片经过`Convolution`层和`MaxPooling`层，并重复多次
2. 经过`Flatten`层
3. 最后经过全连接前馈网络，得到影像辨识的结果

### 2.1 Convolution

- Property1：使用若干个`filter`去检测整张图在该范围内有没有某一个部分的出现
- Property2：将一个`filter`与图片的左上角进行内积，然后根据`stride`移动`filter`，逐步计算内积，继续使用下一个`filter`进行处理

- Convolution与Full Connected的关系：Convolution把一些`weight`拿掉了之后进行计算。

### 2.2 Max Pooling

- 原理：将输出的结果进行分组，然后计算各组的平均或选取最大，将图片进一步缩小

### 2.3 Flatten

- 原理：将所有的`feature map`拉直，然后传入全连接前馈神经网络

## 3 CNN的本质（CNN学到了什么？）

1. `filter`层的作用：仅侦测图中的某个区域
2. 第k层`filter`的本质：使用梯度下降，求取$x^* =\arg \max \limits_x a^k$，其中$\displaystyle a^k = \sum_{i=1}^{11} \sum_{j=1}^{11} a_{ij}^k $ 
3. 全连接层的作用：侦测图中比较大的区域

## 4 CNN的应用

- 围棋：将落子的图像传给CNN进行训练，输入是19\*19的向量，每一个向量的值对应到棋盘上的每一个位置，通过CNN之后，输出下一步落子的位置。

- AlphaGo：符合CNN的3个特点
  1. 仅需要通过一个小区域就可以判断下一步落子的位置，例如第1个`filter`使用的是5\*5
  2. 同样的类型会出现在不同的区域上
  3. 网络架构：输入是一个19\*19\*48的图片，且第1层将输入进行扩展，把原来19\*19的图片外围补上更多的0，让它变成23\*23的图片，其中并没有使用Max Pooling

- 语音：将声音表示成`Spectrogram`(横轴表示时间，纵轴表示该时间里面声音的频率)，并把这个看成一个图片，输入给CNN，在语音上，只考虑在频率方向上移动`filter`，其目的符合获得同样的类型出现在不同的区域，可以用同一个`filter`进行处理。

- 文本：`word sequence`的每一个`word`可以用一个词向量表示，如果两个`word`越接近，词向量在高维的空间上就越接近，被称为`Word Embedding`；将所有句子的`word`排在一起，并将其看成一个图片，输入给CNN，其中`filter`沿着句子里面词汇的顺序来移动,然后通过Max Pooling和全连接层，得到结果。

## 5 总结

&emsp;&emsp;本次任务，主要介绍了CNN的特点、网络结构和相关的应用：
1. CNN具有3个特点：可使用一部分图、同一种类型可以出现在图的不同位置、可以进行图片下采样
2. CNN模型网络结构：多个Convolution和Max pooling的组合结构、Flatten层和全连接前馈神经网络
3. 其他应用举例：围棋、语音、文本
