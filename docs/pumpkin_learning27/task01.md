# Task01 概览西瓜书+南瓜书第1、2章

## 1 术语梳理
- 数据集：记录的集合
- 样本：其中每条记录是关于一个事件或对象的描述
- 属性/特征：反映事件或对象在某方面的表现或性质的事项
- 学习任务分为两大类：监督学习、无监督学习
- 独立同分布：假设样本空间中，全体样本服从一个未知“分布”，获得的每个样本都是独立地从这个分布上采样获得
- 分类：预测值为离散值的问题
- 回归：预测值为连续值的问题

## 2 发展历程与应用
- 推理期：20世纪50年代到70年代，逻辑理论家程序和通用问题求解程序，基于符号知识表示、通过演绎推理技术
- 知识期：从20世纪70年代中期到80年代，专家系统问世，基于符号知识表示、通过获取和利用领域知识建立专家系统
- 从样例中学习：20世纪90年代中期之前，基于神经网络的连接主义学习
- 统计学习：20世纪90年代中期开始，支持向量机、核方法
- 深度学习：21世纪初，很多层的神经网络
- 应用：交叉学科、生物信息学、数据科学、天气预报、能源勘探、环境监测等

## 3 经验误差与过拟合
- 错误率：如果在$m$个样本中有$a$个样本分类错误，则错误率为$E=a/m$
- 误差：学习器的实际预测输出与样本的真实输出之间的差异
- 训练误差/经验误差：学习器在训练集上的误差
- 泛化误差：学习器在新样本上的误差

## 4 评估方法

### 4.1 留出法 
- 概念：直接将数据集$D$划分为两个互斥集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D=S \cup T, S \cap T = \emptyset$，在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计
- 分层采样：保留类别比例的采样范式
- 常用做法：将大约$2/3 \sim 4/5$的样本用于训练，剩余样本用于测试

### 4.2 交叉验证法
- 概念：将数据集$D$划分为$k$个大小相同的互斥子集，满足$D=D_1\cup D_2\cup \cdots \cup  D_k, \quad D_i \cap D_j= \emptyset (i \neq j)$，同样地尽可能保持数据分布的一致性，即采用分层抽样的方法获得这些子集。交叉验证法的思想是：每次用$k-1$个子集的并集作为训练集，余下的那个子集作为测试集，这样就有$K$种训练集/测试集划分的情况，从而可进行$k$次训练和测试，最终返回$k$次测试结果的均值。


- $k$最常用的取值是10

### 4.3 自助法
- 概念：给定包含$m$个样本的数据集$D$，每次随机从$D$中挑选一个样本，将其拷贝放入$D'$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到。重复执行$m$次，就可以得到了包含$m$个样本的数据集$D'$。可以得知在$m$次采样中，样本始终不被采到的概率取极限为：
$$
\lim _{m \rightarrow \infty}\left(1-\frac{1}{m}\right)^{m} \rightarrow \frac{1}{e} \approx 0.368
$$
&emsp;&emsp;这样，通过自助采样，初始样本集D中大约有36.8%的样本没有出现在$D'$中，于是可以将$D'$作为训练集，$D-D'$作为测试集。

## 5 性能度量

### 5.1 错误率/精度
- 错误率定义为$$E(f ; D)=\frac{1}{m} \sum_{i=1}^m I \left(f(x_i) \neq y_i\right)$$
- 精度则定义为$$
\begin{aligned} acc(f ; D) 
&=\frac{1}{m} \sum_{i=1}^{m}I\left(f(x_i)=y_i \right) \\ 
&=1-E(f ; D) 
\end{aligned}$$&emsp;&emsp;

### 5.2 查准率、查全率与F1
- 分类混淆矩阵：  
![分类混淆矩阵](images/ch01/01-Classification-Result-Obfuscation-Matrix.png)
- 查准率$P$：$$P=\frac{TP}{TP+FP}$$
- 查全率$R$：$$R=\frac{TP}{TP+FN}$$


- “P-R曲线”：描述查准/查全率变化的曲线。根据学习器的预测结果（一般为一个实值或概率）对测试样本进行排序，将最可能是“正例”的样本排在前面，最不可能是“正例”的排在后面，按此顺序逐个把样本作为“正例”进行预测，每次计算出当前的P值和R值。


- F1值：计算查准率与查全率的调和平均值
$$F1=\frac{2 \times P \times R}{P + R} = \frac{2 \times TP}{\text{样例总数 + TP - TN}}$$
