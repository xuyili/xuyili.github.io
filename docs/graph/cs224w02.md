# 1.图的基本表示和特征工程学习笔记

学习内容来自：[斯坦福大学CS224W图机器学习公开课-同济子豪兄中文精讲](https://github.com/TommyZihao/zihao_course/tree/main/CS224W#%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6cs224w%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE-%E5%90%8C%E6%B5%8E%E5%AD%90%E8%B1%AA%E5%85%84%E4%B8%AD%E6%96%87%E7%B2%BE%E8%AE%B2)

> 同济子豪兄-中文精讲视频：https://www.bilibili.com/video/BV1pR4y1S7GA
>
> 本讲介绍了图数据挖掘的常见任务、典型方法、应用场景、编程工具。图是描述大自然各种关联现象的通用语言，图无处不在。不同于传统数据分析中样本独立同分布假设，图数据自带了关联结构，需要使用专门的图神经网络进行深度学习。 本讲介绍了斯坦福CS224W公开课的课程大纲；在节点、连接、子图、全图各个层面进行图数据挖掘的典型任务，以及在蛋白质结构预测、生物医药、内容推荐、文献挖掘、社交网络、开源项目评价等领域的应用。
>

## 1.本体笔记



## 2.思考题1

1. **连接层面，存在哪些数据挖掘任务，有何应用场景？**
2. **连接层面可以构造哪些特征？这些特征可以归为哪三类？**
3. **简述Link Prediction的基本流程**
4. **A和B都知道梅西，C和D都知道同济子豪兄，请问哪对人物更容易产生社交连接。可以用哪个特征解释？**
5. **两个节点没有共同好友时，可以用什么特征，将连接编码为D维向量？**
6. **简述Katz Index的算法原理**
7. **如何计算节点U和节点V之间，长度为K的路径个数**
8. **为什么不直接把link两端节点的向量特征concat到一起，作为link的向量特征**

## 3.思考题2

1. **全图层面，存在哪些数据挖掘任务，有何应用场景？**
2. **全图层面可以构造哪些特征？**
3. **全图层面的Graphlet，和节点层面的Graphlet，有什么区别？**
4. **子图匹配，算法复杂度如何计算？**
5. **简述Weisfeiler-Lehman Kernel的算法原理**
6. **Weisfeiler-Lehman Kernel的词汇表（颜色表）是如何构建的？**
7. **Weisfeiler-Lehman Kernel，算法复杂度是多少？**
8. **Weisfeiler-Lehman Kernel和图神经网络（GNN）有什么关系？**
9. **简述Kernel Methods基本原理**
10. **为什么在Graph-level任务中，使用Kernel Methods**
11. **除了Graphlet Kernel和Weisfeiler-Lehman Kernel之外，还有哪些Kernel**
12. **传统图机器学习和特征工程中，哪些特征用到了邻接矩阵Adjacency Matrix？**
13. **如何把无向图节点、连接、全图的特征，推广到有向图？**
14. **如何用代码实现Weisfeiler-Lehman Kernel？**
