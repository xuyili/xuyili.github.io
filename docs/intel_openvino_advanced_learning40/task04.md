# Task04 音频处理、人体姿势识别

## 1 第6课：AI应用中的音频处理

- 图像处理：第1层（卷积层）用于提取图像特征，有时看起来像边缘图像；第2层将提取更高级别的特征....，应用多种尺寸的过滤器，处理缩放、旋转等，最后通过全连接层对图像进行分类，以上是视觉AI的简单描述
- 音频特征提取：信号采样和量化处理，使用傅里叶变换得到音频的频域表示，使用时域和频域叠加形成光谱图（MFCCs），转化为图像表示
- 音频处理：将音频信号转换为光谱图，从而转成类似于图像处理
- 影响音频处理的因素： 
  1. 信号具有可变长度，不同单词的长度差异很大，存在不同长度的停顿或静默时刻，需要确定一个时间窗口
  2. 语境、单词顺序很重要

## 2 第7课：DL-streamer表情和情绪识别

- DL-streamer的新功能：
  1. gvaTrack：添加跟踪元素
  2. gvaMetaConvert：将元数据转换为标准格式
  3. gvaMetaPublish：将此数据传达给其他流水线处理通道或应用
  4. gvaPython：构建自定义Python流水线处理通道元素
- 流水线处理：获取输入视频文件或摄像头或RTSP流、解码、准备推理、运行检测、分类或其他类型的推理
- 流水线处理通道的管理方式：
  1. GST 缓冲区是一种保存帧信息的数据结构，每个流水线处理通道阶段都可以读取gst缓冲区信息用于输入，并可以将信息添加到缓冲区用于输出
  2. 当添加跟踪流水线处理通道阶段时，会查看之前流水线处理通道阶段检测并存储在GST缓冲区中的所有对象并跟踪它们
- 智慧城市示例：
  - 基本架构：设想一下，城市遍布数百、甚至数千个摄像头所有这些摄像头都需要与城市指挥中心通信，假设每6个摄像头与“路口的交互计算机”或“节点”通信，并且每几个交互计算机 都保持与街区的节点进行通信，所有街区都要与城市的云指挥中心通信
  - 场景举例：1号摄像头检测到一张新面孔，并将该信息传输到上游的交互口，交互计算机将提取此面孔的特征，并将其传输给街区计算机，街区节点将从所有交互口计算机 收集输入信息并将其传输至指挥中心。指挥中心可能向下游传达某面孔是嫌疑人的信息，或请求以更高分辨率传输特定摄像头的数据。
- MQTT：使用broker来控制所有通信，每个客户端都可以向broker发送和发布消息，每条消息都属于一个Topic，并且broker知道将消息发送给每个订阅了相应Topic的客户（类似于消息发布与订阅）
